% !TeX root=../main.tex
% در این فایل، عنوان پایان‌نامه، مشخصات خود و چکیده پایان‌نامه را به انگلیسی، وارد کنید.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\latinuniversity{University of Tabriz}
\latinfaculty{Faculty of Electrical and Computer Engineering}
\latindepartment{Computer Engineering Group}
\latinsubject{Computer Engineering}
\latinfield{Computer Systems Architecture}
\latintitle{Human-Object and Human-Pose relation network for human action recognition in still images}
\firstlatinsupervisor{Dr. Abdolhamid Moallemi Khiavi}
%\secondlatinsupervisor{Dr. Alireza Sokhandan Sorkhabi}
\firstlatinadvisor{Dr. Alireza Sokhandan Sorkhabi}
%\secondlatinadvisor{Second Advisor}
\latinname{Mehran}
\latinsurname{Shahmohammadi}
\latinthesisdate{May 2023}
\latinkeywords{
Human Action Recognition in Still Image, Deep Learning, Attention Mechanism, Pose Estimation, Object Detection}
\en-abstract{
The identification and recognition of human activities from a single image pose significant challenges due to the absence of temporal information. Conventional video processing methods are ineffective in this context. To address these challenges, we propose a novel image-based Human Action Recognition (HAR) method that utilizes both Deep Neural Networks (DNNs) and Transformers. Our method effectively compensates for the lack of temporal information by focusing on the image's auxiliary and contextual information.
From a single image, information such as human appearance, pose and objects related to humans can be extracted. These pieces of information encompass crucial details of human actions and deep neural networks are commonly employed today to extract these features.
The Transformer network and Attention Mechanism, initially used in text processing, are now widely utilized in computer vision as well. Recognizing human action in a still image has various applications including surveillance, robotics industry, human-computer interaction programs, frame tagging, and more. In this thesis, important image features are first extracted using deep neural networks. Then, these features are combined with each other using the attention mechanism to perform relational reasoning. The relationship between human and pose, as well as the relationship between human and relevant objects, is identified. The network estimates action based on these relational results. To combine pose with human, limb angle descriptors are used to extract pose features. The VOC 2012 and Stanford40 datasets in the field of human action are used to evaluate the model's performance and train the network. The proposed model's result, combining limb angle descriptors with the output of the relational reasoning component, achieves an accuracy of 92.33\% on the VOC 2012 dataset.
}
