% !TeX root=../main.tex
% در این فایل، عنوان پایان‌نامه، مشخصات خود و چکیده پایان‌نامه را به انگلیسی، وارد کنید.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\latinuniversity{University of Tabriz}
\latinfaculty{Faculty of Electrical and Computer Engineering}
\latindepartment{Computer Engineering Group}
\latinsubject{Computer Engineering}
\latinfield{Computer Systems Architecture}
\latintitle{Human-Object and Human-Pose relation network for human action recognition in still images}
\firstlatinsupervisor{Dr. Abdolhamid Moallemi Khiavi}
%\secondlatinsupervisor{Dr. Alireza Sokhandan Sorkhabi}
\firstlatinadvisor{Dr. Alireza Sokhandan Sorkhabi}
%\secondlatinadvisor{Second Advisor}
\latinname{Mehran}
\latinsurname{Shahmohammadi}
\latinthesisdate{May 2023}
\latinkeywords{
Human Action Recognition in Still Image, Deep Learning, Attention Mechanism, Pose Estimation, Object Detection}
\en-abstract{
The identification and recognition of human activities from a single image pose significant challenges due to the absence of temporal information. Conventional video processing methods are ineffective in this context. To address these challenges, we propose a novel image-based Human Action Recognition (HAR) method that utilizes both Deep Neural Networks (DNNs) and Transformers. Our method effectively compensates for the lack of temporal information by focusing on the image's auxiliary and contextual information.
From a single image, information such as human appearance, pose and objects related to humans can be extracted. These pieces of information encompass crucial details of human actions and deep neural networks are commonly employed today to extract these features. Additionally, another network called Transformer, initially used in text processing applications, is now widely utilized in the field of computer vision and has also proven to be beneficial in human action recognition. 
In this thesis, utilizing deep neural networks, significant image features are first extracted. Subsequently, these features are combined using the Attention Mechanisms to establish a relational understanding. The relationship between humans and their actions, as well as the relationship between humans and related objects, is identified, and the network estimates activities based on these relational findings.
To combine human pose, a Limb Angle Descriptor (LAD) is used to extract pose features. Two datasets, VOC 2012 and Stanford40, in the domain of human activity, are utilized to evaluate the model's performance and train the network. The proposed model, combining the Limb Angle Descriptor with the output of the relational reasoning module, achieves an accuracy of 92.33\% on the VOC 2012 dataset.
}
